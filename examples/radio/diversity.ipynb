{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e7b4cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/johannes.kruse/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "/Users/johannes.kruse/coding/RADio-/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from normative_diversity.RADio.metric import DiversityMetric\n",
    "from functions import *  # This may take a while to load first time\n",
    "from visualize import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba200ccdd710bc4",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "\n",
    "Ensure that the data folder contains the following files:\n",
    "- news.tsv <br>\n",
    "    Tab-separated file as supplied in the MIND dataset. To be usable, entities need to have a Label and a Type. Example: <br>\n",
    "    N12733\tnews\tpolitics\tTitle\t\turl\t[{\"Label\": \"Entity Label\", \"Type\": \"O\"]\t[] <br>\n",
    "- recommendations.json  <br>\n",
    "    JSON files containing the generated recommendations. Should contain the fields impr_index, userid, date and history (optionally ordered by recency). The other columns will be interpreted as 'recommendation' columns, and their names as the name of the algorithm used. Example:\n",
    "     impr_index userid  date        history         lstur           random\n",
    "     34         U1234   13-08-1991  [N5, N4, N3],   [N1, N2, N3],   [N3, N2, N1]\n",
    "<br>    \n",
    "The news.tsv follows the same format as the MIND dataset. The recommendations can be constructed from generating MIND's prediction files, and merging those with the relevant information from the MIND behavior file. For more details about the MIND format, see https://github.com/msnews/msnews.github.io/blob/master/assets/doc/introduction.md The repo currently contains a sample of 100 rows and predictions, which correspond to the news.tsv in MINDsmall_dev. Reach out to us for an example of the full file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da0243358944a11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:29:39.854979Z",
     "start_time": "2024-07-31T12:29:39.847609Z"
    }
   },
   "outputs": [],
   "source": [
    "# the number of unique users that will be sampled for analysis. Set to 0 if no sampling should take place.\n",
    "sample_size = 0\n",
    "\n",
    "# Folder where the necessary files can be found\n",
    "data_folder = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1f8f7acde76b1bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:29:47.492925Z",
     "start_time": "2024-07-31T12:29:39.855984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>url</th>\n",
       "      <th>entities_title</th>\n",
       "      <th>entities_subtitle</th>\n",
       "      <th>absolute_sentiment_score</th>\n",
       "      <th>persons</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N55528</th>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestyleroyals</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "      <td>Shop the notebooks, jackets, and more that the...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAGH0ET.html</td>\n",
       "      <td>[{\"Label\": \"Prince Philip, Duke of Edinburgh\",...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>[Prince Philip, Duke of Edinburgh, Charles, Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N18955</th>\n",
       "      <td>health</td>\n",
       "      <td>medical</td>\n",
       "      <td>Dispose of unwanted prescription drugs during ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAISxPN.html</td>\n",
       "      <td>[{\"Label\": \"Drug Enforcement Administration\", ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N61837</th>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
       "      <td>Lt. Ivan Molchanets peeked over a parapet of s...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAJgNsz.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N53526</th>\n",
       "      <td>health</td>\n",
       "      <td>voices</td>\n",
       "      <td>I Was An NBA Wife. Here's How It Affected My M...</td>\n",
       "      <td>I felt like I was a fraud, and being an NBA wi...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AACk2N6.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"National Basketball Association\", ...</td>\n",
       "      <td>0.1531</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N38324</th>\n",
       "      <td>health</td>\n",
       "      <td>medical</td>\n",
       "      <td>How to Get Rid of Skin Tags, According to a De...</td>\n",
       "      <td>They seem harmless, but there's a very good re...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAAKEkt.html</td>\n",
       "      <td>[{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...</td>\n",
       "      <td>[{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category      subcategory  \\\n",
       "article_id                               \n",
       "N55528      lifestyle  lifestyleroyals   \n",
       "N18955         health          medical   \n",
       "N61837           news        newsworld   \n",
       "N53526         health           voices   \n",
       "N38324         health          medical   \n",
       "\n",
       "                                                        title  \\\n",
       "article_id                                                      \n",
       "N55528      The Brands Queen Elizabeth, Prince Charles, an...   \n",
       "N18955      Dispose of unwanted prescription drugs during ...   \n",
       "N61837      The Cost of Trump's Aid Freeze in the Trenches...   \n",
       "N53526      I Was An NBA Wife. Here's How It Affected My M...   \n",
       "N38324      How to Get Rid of Skin Tags, According to a De...   \n",
       "\n",
       "                                                     subtitle  \\\n",
       "article_id                                                      \n",
       "N55528      Shop the notebooks, jackets, and more that the...   \n",
       "N18955                                                    NaN   \n",
       "N61837      Lt. Ivan Molchanets peeked over a parapet of s...   \n",
       "N53526      I felt like I was a fraud, and being an NBA wi...   \n",
       "N38324      They seem harmless, but there's a very good re...   \n",
       "\n",
       "                                                      url  \\\n",
       "article_id                                                  \n",
       "N55528      https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
       "N18955      https://assets.msn.com/labs/mind/AAISxPN.html   \n",
       "N61837      https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
       "N53526      https://assets.msn.com/labs/mind/AACk2N6.html   \n",
       "N38324      https://assets.msn.com/labs/mind/AAAKEkt.html   \n",
       "\n",
       "                                               entities_title  \\\n",
       "article_id                                                      \n",
       "N55528      [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
       "N18955      [{\"Label\": \"Drug Enforcement Administration\", ...   \n",
       "N61837                                                     []   \n",
       "N53526                                                     []   \n",
       "N38324      [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...   \n",
       "\n",
       "                                            entities_subtitle  \\\n",
       "article_id                                                      \n",
       "N55528                                                     []   \n",
       "N18955                                                     []   \n",
       "N61837      [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...   \n",
       "N53526      [{\"Label\": \"National Basketball Association\", ...   \n",
       "N38324      [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...   \n",
       "\n",
       "            absolute_sentiment_score  \\\n",
       "article_id                             \n",
       "N55528                        0.0516   \n",
       "N18955                        0.2263   \n",
       "N61837                        0.5719   \n",
       "N53526                        0.1531   \n",
       "N38324                        0.0000   \n",
       "\n",
       "                                                      persons  \n",
       "article_id                                                     \n",
       "N55528      [Prince Philip, Duke of Edinburgh, Charles, Pr...  \n",
       "N18955                                                     []  \n",
       "N61837                                                     []  \n",
       "N53526                                                     []  \n",
       "N38324                                                     []  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the articles\n",
    "articles = process_articles(data_folder + \"/news.tsv\")\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93721d014bb44917",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:29:50.560765Z",
     "start_time": "2024-07-31T12:29:47.493934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impr_index</th>\n",
       "      <th>userid</th>\n",
       "      <th>date</th>\n",
       "      <th>history</th>\n",
       "      <th>lstur</th>\n",
       "      <th>nrms</th>\n",
       "      <th>pop</th>\n",
       "      <th>random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>758</td>\n",
       "      <td>U27694</td>\n",
       "      <td>2019-11-15 05:07:18</td>\n",
       "      <td>[N29929, N26727, N57737, N32312, N31801, N6271...</td>\n",
       "      <td>[N48487, N6916, N37204, N30290, N53615, N5940,...</td>\n",
       "      <td>[N37204, N48487, N53615, N30290, N20036, N2351...</td>\n",
       "      <td>[N36786, N11930, N36940, N63421, N53242, N1968...</td>\n",
       "      <td>[N60939, N36786, N6916, N30290, N60975, N15719...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>1667</td>\n",
       "      <td>U19405</td>\n",
       "      <td>2019-11-15 10:26:09</td>\n",
       "      <td>[N30353, N59359, N5905, N41298, N4526, N37131,...</td>\n",
       "      <td>[N30290, N19990, N31958, N42844, N5472, N60724...</td>\n",
       "      <td>[N19990, N60724, N30290, N16327, N31958, N5940...</td>\n",
       "      <td>[N37352, N58098, N55237, N60724, N55913, N5077...</td>\n",
       "      <td>[N5472, N31958, N19990, N36779, N42844, N19990...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>1769</td>\n",
       "      <td>U37816</td>\n",
       "      <td>2019-11-15 12:45:53</td>\n",
       "      <td>[N21383, N250, N5102, N54575, N58267, N45954, ...</td>\n",
       "      <td>[N6950, N35815, N38620, N58748, N61053, N28072...</td>\n",
       "      <td>[N35815, N63342, N54593, N38324, N24802, N6072...</td>\n",
       "      <td>[N6074, N11930, N38324, N29862, N496, N23336, ...</td>\n",
       "      <td>[N58188, N31141, N6916, N24802, N39928, N48740...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>2279</td>\n",
       "      <td>U63512</td>\n",
       "      <td>2019-11-15 07:55:54</td>\n",
       "      <td>[N56586, N63842, N36739, N29177, N13137, N3016...</td>\n",
       "      <td>[N30290, N42844, N19990, N20187, N5940, N36779...</td>\n",
       "      <td>[N23513, N30290, N5940, N19990, N36779, N42844...</td>\n",
       "      <td>[N36786, N58098, N36940, N31958, N46976, N4284...</td>\n",
       "      <td>[N42844, N23355, N30290, N42844, N60757, N2003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3074</th>\n",
       "      <td>3075</td>\n",
       "      <td>U76977</td>\n",
       "      <td>2019-11-15 12:42:00</td>\n",
       "      <td>[N42299, N47069, N47069, N6956, N16233, N51706...</td>\n",
       "      <td>[N28682, N31141, N20477, N61811, N59933, N2333...</td>\n",
       "      <td>[N5472, N20477, N61811, N31141, N6400, N11150,...</td>\n",
       "      <td>[N16344, N38311, N18708, N11930, N29862, N5809...</td>\n",
       "      <td>[N59933, N13601, N19990, N53201, N44621, N5472...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      impr_index  userid                date  \\\n",
       "757          758  U27694 2019-11-15 05:07:18   \n",
       "1666        1667  U19405 2019-11-15 10:26:09   \n",
       "1768        1769  U37816 2019-11-15 12:45:53   \n",
       "2278        2279  U63512 2019-11-15 07:55:54   \n",
       "3074        3075  U76977 2019-11-15 12:42:00   \n",
       "\n",
       "                                                history  \\\n",
       "757   [N29929, N26727, N57737, N32312, N31801, N6271...   \n",
       "1666  [N30353, N59359, N5905, N41298, N4526, N37131,...   \n",
       "1768  [N21383, N250, N5102, N54575, N58267, N45954, ...   \n",
       "2278  [N56586, N63842, N36739, N29177, N13137, N3016...   \n",
       "3074  [N42299, N47069, N47069, N6956, N16233, N51706...   \n",
       "\n",
       "                                                  lstur  \\\n",
       "757   [N48487, N6916, N37204, N30290, N53615, N5940,...   \n",
       "1666  [N30290, N19990, N31958, N42844, N5472, N60724...   \n",
       "1768  [N6950, N35815, N38620, N58748, N61053, N28072...   \n",
       "2278  [N30290, N42844, N19990, N20187, N5940, N36779...   \n",
       "3074  [N28682, N31141, N20477, N61811, N59933, N2333...   \n",
       "\n",
       "                                                   nrms  \\\n",
       "757   [N37204, N48487, N53615, N30290, N20036, N2351...   \n",
       "1666  [N19990, N60724, N30290, N16327, N31958, N5940...   \n",
       "1768  [N35815, N63342, N54593, N38324, N24802, N6072...   \n",
       "2278  [N23513, N30290, N5940, N19990, N36779, N42844...   \n",
       "3074  [N5472, N20477, N61811, N31141, N6400, N11150,...   \n",
       "\n",
       "                                                    pop  \\\n",
       "757   [N36786, N11930, N36940, N63421, N53242, N1968...   \n",
       "1666  [N37352, N58098, N55237, N60724, N55913, N5077...   \n",
       "1768  [N6074, N11930, N38324, N29862, N496, N23336, ...   \n",
       "2278  [N36786, N58098, N36940, N31958, N46976, N4284...   \n",
       "3074  [N16344, N38311, N18708, N11930, N29862, N5809...   \n",
       "\n",
       "                                                 random  \n",
       "757   [N60939, N36786, N6916, N30290, N60975, N15719...  \n",
       "1666  [N5472, N31958, N19990, N36779, N42844, N19990...  \n",
       "1768  [N58188, N31141, N6916, N24802, N39928, N48740...  \n",
       "2278  [N42844, N23355, N30290, N42844, N60757, N2003...  \n",
       "3074  [N59933, N13601, N19990, N53201, N44621, N5472...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithms, predictions = process_recommendations(\n",
    "    data_folder + \"/recommendations_sample.json\", sample_size\n",
    ")\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332e3482cf370902",
   "metadata": {},
   "source": [
    "# Configuring the Diversity metrics\n",
    "\n",
    "In the next section we are configuring the normative diversity metrics. Following the RADio framework, we conceptualize diversity as **a rank-aware divergence score between a recommendation and a context**. \n",
    "\n",
    "$$\n",
    "D^*_f(P,Q) = \\sum_x Q^*(x) f (\\frac{P^*(x)}{Q^*(x)})\n",
    "$$\n",
    "\n",
    "where  *x* refers to the relevant feature to consider; *P* to the recommendation, and *Q* to the context. Both the recommendation *P* and context *Q* can be set up to be *rank-aware*, meaning, discounting articles lower on the list. <br>\n",
    "<br>\n",
    "\n",
    "The relevant feature to consider and which context to consider is very domain and application dependent. For example, one could be interested in comparing the article categories (x) in the recommendation (P) to the categories in a users' reading history (Q). Or, to compare the mentions of political parties (x) in the recommendation to the distribution of parties in government (Q). In this example we configure the metrics as in DART, but note that this is not necessarily the right configuration for *your* application.    <br>\n",
    "<br>\n",
    "For each metric, we need to configure the following things: \n",
    "-   *feature_type*: cat/cat_m/cont; Whether the feature type single-value categorical (cat), multi-value categorical (cat_m) or continuous (cont)\n",
    "-   *rank_aware_recommendation*: True/False; whether the recommendation should be rank-aware\n",
    "-   *rank_aware_context*: True/False; whether the context should be rank-aware\n",
    "-   *divergence*: JSD/KL; which divergence metric to use\n",
    "-   *context*: dynamic/static; for efficiency, whether the context distribution is stable or is expected to be different for every recommendation\n",
    "<br>\n",
    "<br>Both the recommendation and the context should be expressed as a *list*. If it is meant to be rank-aware, it is important that the first item in the list should be counted the strongest, and the last one the least.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6baeecc1384c531",
   "metadata": {},
   "source": [
    "## Calibration\n",
    "\n",
    "Calibration calculates to which extent a recommendation is tailored to a user's preferences. In this initialization, we compare the article categories in the recommendation to what a user has consumed in the past. \n",
    "\n",
    "**Feature**: article category <br>\n",
    "**Context**: User history <br>\n",
    "**Feature type**: categorical, here single but could be multi <br>\n",
    "**Rank-aware**: both recommendation and context <br>\n",
    "**Desired value**: Low divergence if you want to tailor to a user's preferences; higher if you want to help them encounter new things\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d9048c006889e50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:29:50.569524Z",
     "start_time": "2024-07-31T12:29:50.561778Z"
    }
   },
   "outputs": [],
   "source": [
    "Calibration = DiversityMetric(\n",
    "    feature_type=\"cat\",\n",
    "    rank_aware_recommendation=True,\n",
    "    rank_aware_context=True,\n",
    "    divergence=\"JSD\",\n",
    "    context=\"dynamic\",\n",
    ")\n",
    "\n",
    "\n",
    "def calculate_calibration(recommendations, history):\n",
    "    scores = []\n",
    "    context_features = make_list(history, \"category\")\n",
    "    for recommendation in recommendations:\n",
    "        recommendation_features = make_list(recommendation, \"category\")\n",
    "        if context_features and recommendation_features:\n",
    "            scores.append(\n",
    "                Calibration.compute(context_features, recommendation_features)\n",
    "            )\n",
    "        else:\n",
    "            scores.append(None)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ba6a6d8689f29c",
   "metadata": {},
   "source": [
    "## Fragmentation\n",
    "\n",
    "Fragmentation calculates to what extent users that received recommendation have a shared understanding, or: the amount of overlap. Ideally, we would want individual articles to be clustered into stories, as users can read slightly different articles about the same topic but still have a shared understanding. However, as this information is not present in this dataset, we use article subcategory as an approximation. See also \"Improving and Evaluating the Detection of Fragmentation in News Recommendations with the Clustering of News Story Chains\" by Polimeno et al. for inspiration on how story clustering could work. \n",
    "\n",
    "\n",
    "Fragmentation is conceptually related to the filter bubble. When there is low Fragmentation, users see similar topics and thus have a shared understanding of the system. On the other hand, with high Fragmentation what people receive does not overlap: they exist in a personal 'bubble'. This can still be desirable, for example when the goal is to help users specialize in their domain of choice. <br>\n",
    "As we need to compare recommendations to other users' recommendations, Fragmentation can be computationally heavy. Its performance is highly dependent on the number of other users we compare to. \n",
    "\n",
    "**Feature**: article category <br>\n",
    "**Context**: Other users' recommendations <br>\n",
    "**Feature type**: categorical, single <br>\n",
    "**Rank-aware**: both recommendation and context <br>\n",
    "**Desired value**: low when we want a shared understanding, high when we want specialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89b048d968d00cd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:29:50.575702Z",
     "start_time": "2024-07-31T12:29:50.570542Z"
    }
   },
   "outputs": [],
   "source": [
    "Fragmentation = DiversityMetric(\n",
    "    feature_type=\"cat\",\n",
    "    rank_aware_recommendation=True,\n",
    "    rank_aware_context=True,\n",
    "    divergence=\"JSD\",\n",
    "    context=\"dynamic\",\n",
    ")\n",
    "\n",
    "\n",
    "def calculate_fragmentation(recommendations, user_sample):\n",
    "    scores = []\n",
    "    for index, recommendation in enumerate(recommendations):\n",
    "        alg = recommendations.index[index]\n",
    "        recommendation_features = make_list(recommendation, \"subcategory\")\n",
    "        score_per_user = 0\n",
    "        recommendations_to_other_users = user_sample[alg]\n",
    "        for x in recommendations_to_other_users:\n",
    "            context_features = make_list(x, \"subcategory\")\n",
    "            score_per_user += Fragmentation.compute(\n",
    "                recommendation_features, context_features\n",
    "            )\n",
    "        average = score_per_user / len(user_sample)\n",
    "        scores.append(average)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3646c5eb7b0411",
   "metadata": {},
   "source": [
    "## Activation\n",
    "\n",
    "The goal of Activation is to express the affect of the content in the recommendation. We approximate affect as the absolute sentiment score; we care about the strength of the emotion, not about it's valence (though there could be a lot more discussion about this). Mostly, we want to know whether the recommendation is very different from the overall content on the platform. Therefore, we set feature type to continuous (sentiment score is between 0 and 1) the context as static. Since the sentiment score will be binned, we also specify the desired number of bins.\n",
    "\n",
    "**Feature**: Absolute sentiment scores <br>\n",
    "**Context**: All articles published <br>\n",
    "**Feature type**: continuous <br>\n",
    "**Rank-aware**: Only the recommendation <br>\n",
    "**Bins**: 10 <br>\n",
    "**Desired value**: Up to interpretation, and dependent on a) whether the general tone of articles published is emotional or neutral, and b) whether we want this recommendation to reflect that tone or not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79d32d3ae671142",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:29:50.589480Z",
     "start_time": "2024-07-31T12:29:50.577218Z"
    }
   },
   "outputs": [],
   "source": [
    "Activation = DiversityMetric(\n",
    "    feature_type=\"cont\",\n",
    "    rank_aware_recommendation=True,\n",
    "    rank_aware_context=False,\n",
    "    divergence=\"JSD\",\n",
    "    bins=10,\n",
    "    context=\"static\",\n",
    ")\n",
    "\n",
    "# This variable helps the metrics to be calculated more efficiently, as we don't need to retrieve the sentiment scores of all articles every time.\n",
    "all_article_sentiments = list(articles[\"absolute_sentiment_score\"])\n",
    "\n",
    "\n",
    "def calculate_activation(recommendations):\n",
    "    scores = []\n",
    "    context_features = all_article_sentiments\n",
    "    for recommendation in recommendations:\n",
    "        recommendation_features = make_list(recommendation, \"absolute_sentiment_score\")\n",
    "        if context_features and recommendation_features:\n",
    "            activation = Activation.compute(recommendation_features, context_features)\n",
    "            scores.append(activation)\n",
    "        else:\n",
    "            scores.append(None)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbdbfdef75b25a2",
   "metadata": {},
   "source": [
    "## Representation\n",
    "\n",
    "Representation aims to express to what extent the recommendation is representative of different people/groups in society. Usually we conceptualize this in the context of politics; meaning, the relevant features are the politicians mentioned in the texts. However, this information is not available in MIND. To still show how this metric would work theoretically we use *all* entities of type 'P' as an approximation. 'Representative' can also be conceptualized in different ways. We could want all groups to be represented equally; inversely to give a larger platform to marginalized groups; or reflective of society, for example by comparing to political party distribution in government. Here, we compare to the people mentioned in the dataset. We also apply the Representation metric **only** to articles from the 'news' category.  \n",
    "\n",
    "**Feature**: People mentioned <br>\n",
    "**Context**: All articles published <br>\n",
    "**Feature type**: categorical, multi <br>\n",
    "**Rank-aware**: Only the recommendation <br>\n",
    "**Desired value**: Low if we want the recommendation to reflect the chosen context distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29a8f5be3291a53e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:29:50.659954Z",
     "start_time": "2024-07-31T12:29:50.590488Z"
    }
   },
   "outputs": [],
   "source": [
    "Representation = DiversityMetric(\n",
    "    feature_type=\"cat_m\",\n",
    "    discount_recommendation=True,\n",
    "    discount_context=False,\n",
    "    divergence=\"JSD\",\n",
    "    context=\"static\",\n",
    ")\n",
    "\n",
    "# Only apply Representation to hard news\n",
    "news = articles[articles[\"category\"] == \"news\"]\n",
    "# This variable helps the metrics to be calculated more efficiently, as we don't need to retrieve the sentiment scores of all articles every time.\n",
    "all_news_persons = list(news[news[\"persons\"].map(len) > 0].persons)\n",
    "\n",
    "\n",
    "def calculate_representation(recommendations):\n",
    "    scores = []\n",
    "    context_features = all_news_persons\n",
    "    for recommendation in recommendations:\n",
    "        # only consider the articles in the recommendation of the 'news' category\n",
    "        is_news = news.index.intersection(recommendation)\n",
    "        # the column 'persons' has already been constructed during preprocessing\n",
    "        recommendation_features = make_list(is_news, \"persons\")\n",
    "        if context_features and recommendation_features:\n",
    "            representation = Representation.compute(\n",
    "                recommendation_features, context_features\n",
    "            )\n",
    "            scores.append(representation)\n",
    "        else:\n",
    "            scores.append(None)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592570e5b14d73c1",
   "metadata": {},
   "source": [
    "## Alternative Voices\n",
    "\n",
    "With Alternative Voices, we aim to express whether the recommendation exposes readers to people different from themselves. Here, the focus should lie on people from marginalized groups. However, this information is not present in the MIND dataset, and same as with Representation, we configure the metric to consider the people mentioned in the recommendation. However, different to Representation, the context distribution is the people that have been mentioned in the users' reading history. Note that it is very likely that there is zero overlap between the people in the reading history and the people in the recommendation; in the current setup, the score is expected to mostly be 1. \n",
    "\n",
    "**Feature**: People mentioned <br>\n",
    "**Context**: The user's history <br>\n",
    "**Feature type**: categorical, multi <br>\n",
    "**Rank-aware**: Both the recommendation and the context<br>\n",
    "**Desired value**: Higher divergence if we want the user to encounter new perspectives; lower if we want them to find their niche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61391c8eab6a3a40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:29:50.665060Z",
     "start_time": "2024-07-31T12:29:50.660960Z"
    }
   },
   "outputs": [],
   "source": [
    "AlternativeVoices = DiversityMetric(\n",
    "    # we currently don't have this information\n",
    "    feature_type=\"cat_m\",\n",
    "    discount_recommendation=True,\n",
    "    discount_context=True,\n",
    "    divergence=\"JSD\",\n",
    "    context=\"dynamic\",\n",
    ")\n",
    "\n",
    "\n",
    "def calculate_alternative_voices(recommendations, history):\n",
    "    scores = []\n",
    "    context_features = make_list(history, \"persons\")\n",
    "    for recommendation in recommendations:\n",
    "        recommendation_features = make_list(recommendation, \"persons\")\n",
    "        if context_features and recommendation_features:\n",
    "            alternative_voices = AlternativeVoices.compute(\n",
    "                recommendation_features, context_features\n",
    "            )\n",
    "            scores.append(alternative_voices)\n",
    "        else:\n",
    "            scores.append(None)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c931b40b8fdb5aa8",
   "metadata": {},
   "source": [
    "# Calculating the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b5a4cb7d13d52d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T12:29:50.670484Z",
     "start_time": "2024-07-31T12:29:50.666065Z"
    }
   },
   "outputs": [],
   "source": [
    "def metrics(row):\n",
    "    recommendations = row[algorithms]\n",
    "    history = row[\"history\"]\n",
    "\n",
    "    calibration = calculate_calibration(recommendations, history)\n",
    "\n",
    "    user_sample = predictions.sample(5)[algorithms]\n",
    "    fragmentation = calculate_fragmentation(recommendations, user_sample)\n",
    "\n",
    "    activation = calculate_activation(recommendations)\n",
    "\n",
    "    representation = calculate_representation(recommendations)\n",
    "\n",
    "    alternative_voices = calculate_alternative_voices(recommendations, history)\n",
    "\n",
    "    return calibration, fragmentation, activation, representation, alternative_voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25bfceb7b63c6c4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T13:35:16.081611Z",
     "start_time": "2024-07-31T12:29:50.671489Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:05<00:00, 25.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the metrics\n",
    "predictions[\"metrics\"] = predictions.progress_apply(metrics, axis=1)\n",
    "# Make each metric go to its own column\n",
    "(\n",
    "    predictions[\"calibration\"],\n",
    "    predictions[\"fragmentation\"],\n",
    "    predictions[\"activation\"],\n",
    "    predictions[\"representation\"],\n",
    "    predictions[\"alternative_voices\"],\n",
    ") = zip(*predictions.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d596e9dbc130af",
   "metadata": {},
   "source": [
    "# Visualizing results\n",
    "Change the value of parameter 'metric' to visualize any of the other metrics. \n",
    "- calibration\n",
    "- fragmentation\n",
    "- activation\n",
    "- representation\n",
    "- alternative_voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bb555259147bf15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T13:35:16.093071Z",
     "start_time": "2024-07-31T13:35:16.084735Z"
    }
   },
   "outputs": [],
   "source": [
    "metric = \"calibration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35b2983dcc9a038c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T13:35:22.934611Z",
     "start_time": "2024-07-31T13:35:16.099186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                date       lstur        nrms         pop  \\\n",
      "count                            137  134.000000  134.000000  134.000000   \n",
      "mean   2019-11-15 10:13:08.124087808    0.549152    0.540320    0.643823   \n",
      "min              2019-11-15 00:37:33    0.000000    0.000000    0.000000   \n",
      "25%              2019-11-15 07:15:16    0.442211    0.435870    0.564227   \n",
      "50%              2019-11-15 10:24:31    0.528804    0.538144    0.656484   \n",
      "75%              2019-11-15 12:53:55    0.644875    0.650099    0.728508   \n",
      "max              2019-11-15 21:14:50    0.994280    0.994280    0.994280   \n",
      "std                              NaN    0.168798    0.175798    0.142447   \n",
      "\n",
      "           random  \n",
      "count  134.000000  \n",
      "mean     0.640882  \n",
      "min      0.000000  \n",
      "25%      0.540583  \n",
      "50%      0.648558  \n",
      "75%      0.756698  \n",
      "max      0.994280  \n",
      "std      0.165859  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvisualize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/coding/RADio-/examples/radio/visualize.py:74\u001b[0m, in \u001b[0;36mvisualize\u001b[0;34m(df, metric, algorithms)\u001b[0m\n\u001b[1;32m     71\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[metric])\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mdescribe())\n\u001b[0;32m---> 74\u001b[0m \u001b[43mdistplot_per_user\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m lineplot(result, metric)\n",
      "File \u001b[0;32m~/coding/RADio-/examples/radio/visualize.py:17\u001b[0m, in \u001b[0;36mdistplot_per_user\u001b[0;34m(df, algorithms, metric)\u001b[0m\n\u001b[1;32m     15\u001b[0m fig \u001b[38;5;241m=\u001b[39m ff\u001b[38;5;241m.\u001b[39mcreate_distplot(data, group_labels, bin_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, show_hist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m fig\u001b[38;5;241m.\u001b[39mupdate_layout(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDist Plot of average values for \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m metric \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m per user\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/coding/RADio-/venv/lib/python3.11/site-packages/plotly/basedatatypes.py:3410\u001b[0m, in \u001b[0;36mBaseFigure.show\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3377\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3378\u001b[0m \u001b[38;5;124;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[1;32m   3379\u001b[0m \u001b[38;5;124;03mspecified by the renderer argument\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3406\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[1;32m   3407\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3408\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[0;32m-> 3410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/coding/RADio-/venv/lib/python3.11/site-packages/plotly/io/_renderers.py:394\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         )\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 394\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    395\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    396\u001b[0m         )\n\u001b[1;32m    398\u001b[0m     ipython_display\u001b[38;5;241m.\u001b[39mdisplay(bundle, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# external renderers\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "visualize_metric(predictions, metric, algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9c019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
